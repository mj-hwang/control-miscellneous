{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Quadratic System and Variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Base LQR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Formulation\n",
    "\n",
    "The LQR system assumes following two conditions for $t = 1,2, ..., T$.\n",
    "\n",
    "- **linear dynamical system**\n",
    "$$x_t = Ax_t + Bu_t$$\n",
    "    \n",
    "- **quadratic cost function**\n",
    "$$c(x_t, u_t) = {x_t}^\\top Qx_t + {u_t}^\\top Ru_t$$\n",
    "\n",
    "\n",
    "We would like to solve the optimal control problem shown below.\n",
    "\n",
    "$$\\min_{x,u} \\sum_{t=0}^{T-1} ({x_t}^\\top  Q x_t + {u_t}^\\top  R u_t) \\\\ \\text{s.t. }x_{t+1} = A x_t + B u_t$$\n",
    "\n",
    "*In the caes of the infinite horizon problem, $T$ is infinity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_dim = 4 # state dimension\n",
    "a_dim = 3 # action dimension\n",
    "A = np.random(s_dim, s_dim)\n",
    "B = np.random(s_dim, a_dim)\n",
    "\n",
    "\n",
    "# check if the problem is controllable\n",
    "for i in range(4):\n",
    "    lst.append(A @ lst[-1]) \n",
    "np.linalg.matrix_rank(np.hstack(lst))\n",
    "\n",
    "Q = np.eye(s_dim)\n",
    "R = np.eye(a_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Solution with Value Iteration\n",
    "\n",
    "We first define a cost-to-go function $J_i$ in order to find a optimal policy for a $i$-step horizon.\n",
    "\n",
    "$$J_{i+1}(x) = \\min_u[x^\\top Qx + u^\\top  Ru + J_i(Ax + Bu)]$$ \n",
    "\n",
    "Then, by setting the gradient w.r.t $u$ to zero, we get the following result.\n",
    "\n",
    "for $i=1,2,3,...$\n",
    "\n",
    "- **optimal policy**\n",
    "    - $\\pi(x) = K_{i}x$, where\n",
    "      $$K_{i} = -(R + B^{\\top} P_{i-1} B)^{-1} B^{\\top} P_{i-1} A$$\n",
    "    \n",
    "    \n",
    "- **quadratic cost function**\n",
    "    - $J_i(x) = x^\\top P_{i}x$, where\n",
    "      $$P_i = Q + {K_i}^{\\top}R K_i + (A + B K_i)^{\\top} P_{i-1} (A + B K_i)$$\n",
    "    \n",
    "**$P_0 = 0$*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lqr_infinite(A, B, Q, R, s_dim=4, a_dim=3, threshold=1e-4):\n",
    "    P, K_current = np.eye(s_dim), np.zeros((s_dim, a_dim))\n",
    "    while True:\n",
    "        K_new = -np.linalg.inv(R + B.T @ P @ B) @ B.T @ P @ A\n",
    "        if np.linalg.norm(K_new - K_current) <= threshold:\n",
    "            break\n",
    "        else:\n",
    "            K_current = K_new\n",
    "            P = Q + K_current.T @ R @ K_current + (A + B @ K_current).T @ P @ (A + B @ K_current)\n",
    "    return K_new, P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
